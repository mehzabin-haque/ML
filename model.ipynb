{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from gensim.models import FastText\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48930, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mlb_dataset.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hate\n",
       "1    29046\n",
       "0    19884\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(dataset, stratify_column, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: pd.DataFrame, the input dataset.\n",
    "    - stratify_column: str, the column used for stratified splitting.\n",
    "    - train_ratio: float, the proportion of the dataset for training (default 0.7).\n",
    "    - val_ratio: float, the proportion of the dataset for validation (default 0.2).\n",
    "    - test_ratio: float, the proportion of the dataset for testing (default 0.1).\n",
    "    - random_state: int, random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - train_data, val_data, test_data: pd.DataFrames, the split datasets.\n",
    "    \"\"\"\n",
    "    # Ensure the split ratios sum to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1.\"\n",
    "\n",
    "    # Initial train + validation split\n",
    "    train_data, temp_data = train_test_split(\n",
    "        dataset,\n",
    "        test_size=(val_ratio + test_ratio),\n",
    "        random_state=random_state,\n",
    "        stratify=dataset[stratify_column] if stratify_column else None\n",
    "    )\n",
    "\n",
    "    # Split the remaining data into validation and test sets\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data,\n",
    "        test_size=test_ratio / (val_ratio + test_ratio),\n",
    "        random_state=random_state,\n",
    "        stratify=temp_data[stratify_column] if stratify_column else None\n",
    "    )\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shazzad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "bengali_stopwords = set(stopwords.words('bengali'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing unnecessary characters and symbols.\"\"\"\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Keep Bengali characters and whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text, tokenizer):\n",
    "    \"\"\"Tokenizes text using Bangla BERT tokenizer.\"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Removes Bengali stopwords from tokens.\"\"\"\n",
    "    return [token for token in tokens if token not in bengali_stopwords]\n",
    "\n",
    "def preprocess_text(text, tokenizer):\n",
    "    \"\"\"Combines cleaning, tokenization, and stopword removal.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text, tokenizer)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(df, stratify_column='hate')\n",
    "\n",
    "train_data['processed_sentence'] = train_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))\n",
    "val_data['processed_sentence'] = val_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))\n",
    "test_data['processed_sentence'] = test_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_sentence'] = df['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(corpus, embedding_dim=100, window=5, min_count=1, sg=1):\n",
    "    \"\"\"\n",
    "    Trains a FastText embedding model using gensim.\n",
    "\n",
    "    Parameters:\n",
    "    - corpus: list of lists, tokenized sentences.\n",
    "    - embedding_dim: int, size of word vectors.\n",
    "    - window: int, context window size.\n",
    "    - min_count: int, minimum word frequency for inclusion.\n",
    "    - sg: int, skip-gram (1) or CBOW (0).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained FastText model.\n",
    "    \"\"\"\n",
    "    model = FastText(\n",
    "        sentences=corpus, \n",
    "        vector_size=embedding_dim, \n",
    "        window=window, \n",
    "        min_count=min_count, \n",
    "        sg=sg\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_data['processed_sentence'].tolist()\n",
    "fasttext_model = train_fasttext(corpus)\n",
    "\n",
    "fasttext_model.save(\"fasttext_embeddings.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence_tokens, model):\n",
    "    \"\"\"\n",
    "    Generates sentence embeddings by averaging word embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - sentence_tokens: list, tokens in a sentence.\n",
    "    - model: FastText model.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Sentence embedding vector.\n",
    "    \"\"\"\n",
    "    embeddings = [model.wv[word] for word in sentence_tokens if word in model.wv]\n",
    "    if len(embeddings) == 0:  # Handle case with no valid tokens\n",
    "        return np.zeros(model.vector_size)\n",
    "    return sum(embeddings) / len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fasttext_embedding'] = df['processed_sentence'].apply(lambda tokens: sentence_embedding(tokens, fasttext_model))\n",
    "train_data['fasttext_embedding'] = train_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))\n",
    "val_data['fasttext_embedding'] = val_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))\n",
    "test_data['fasttext_embedding'] = test_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sentence_embedding(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): Input text\n",
    "    Returns:\n",
    "        torch.Tensor of shape [bert_hidden_size]\n",
    "    \"\"\"\n",
    "    inputs = bert_tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    # Inference with no gradient to save memory and compute\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    # outputs.last_hidden_state has shape [batch_size, seq_len, hidden_dim]\n",
    "    # If you're only handling a single text, you can squeeze the batch dimension\n",
    "    return outputs.last_hidden_state.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_embeddings(tokens, fasttext_model, bert_embeddings, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tokens (list): List of tokens\n",
    "        fasttext_model: Gensim's FastText model\n",
    "        bert_embeddings (torch.Tensor): BERT embeddings on GPU\n",
    "        embedding_dim (int): Dimension of the FastText embeddings\n",
    "    Returns:\n",
    "        torch.Tensor of shape [len(tokens), embedding_dim + bert_hidden_size]\n",
    "    \"\"\"\n",
    "    combined_embeddings = []\n",
    "\n",
    "    for idx, token in enumerate(tokens):\n",
    "        # 1. Get FastText vector (on CPU), then move to GPU\n",
    "        if token in fasttext_model.wv:\n",
    "            fasttext_vec = fasttext_model.wv[token]\n",
    "        else:\n",
    "            fasttext_vec = np.zeros(embedding_dim)\n",
    "        fasttext_vec = torch.tensor(fasttext_vec, dtype=torch.float32, device=device)\n",
    "\n",
    "        # 2. Get the corresponding BERT embedding (already on GPU)\n",
    "        if idx < bert_embeddings.size(0):\n",
    "            bert_vec = bert_embeddings[idx]\n",
    "        else:\n",
    "            bert_vec = torch.zeros_like(bert_embeddings[0], device=device)\n",
    "\n",
    "        # 3. Concatenate FastText and BERT embedding along the last dimension\n",
    "        combined_vec = torch.cat((fasttext_vec, bert_vec), dim=0)\n",
    "        combined_embeddings.append(combined_vec)\n",
    "\n",
    "    # Convert list of tensors to a single tensor of shape [num_tokens, total_dim]\n",
    "    combined_embeddings = torch.stack(combined_embeddings)\n",
    "    return combined_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_safe(text, fasttext_model):\n",
    "    \"\"\"\n",
    "    Returns a zero embedding if the text is empty\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        # For example, return a zero tensor with shape [1, your_dimension]\n",
    "        # or skip. This is up to your design.\n",
    "        return torch.zeros((1, 868), device=device)  # If your BERT hidden dim is 768\n",
    "    tokens = text.split()\n",
    "    bert_emb = bert_sentence_embedding(\" \".join(tokens))  # get_bert_embeddings also on GPU\n",
    "    return combine_embeddings(tokens, fasttext_model, bert_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_sentence'].apply(lambda tokens: ' '.join(tokens))\n",
    "y = df['hate']\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.125, random_state=42, stratify=y_train_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train embeddings: 100%|██████████| 34251/34251 [05:22<00:00, 106.16it/s]\n",
      "Generating test embeddings: 100%|██████████| 9786/9786 [01:33<00:00, 105.04it/s]\n",
      "Generating val embeddings: 100%|██████████| 4893/4893 [00:46<00:00, 104.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = [\n",
    "    get_embeddings_safe(tokens, fasttext_model) \n",
    "    for tokens in tqdm(X_train, desc=\"Generating train embeddings\")\n",
    "]\n",
    "test_embeddings = [\n",
    "    get_embeddings_safe(tokens, fasttext_model) \n",
    "    for tokens in tqdm(X_test, desc=\"Generating test embeddings\")\n",
    "]\n",
    "val_embeddings = [\n",
    "    get_embeddings_safe(tokens, fasttext_model) \n",
    "    for tokens in tqdm(X_val, desc=\"Generating val embeddings\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx].float(), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes, dropout=0.5):\n",
    "        super(HAN, self).__init__()\n",
    "\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.word_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.sentence_lstm = nn.LSTM(2 * hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.sentence_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.fc = nn.Linear(2 * hidden_dim, num_classes)\n",
    "\n",
    "    def attention(self, lstm_output, attention_layer):\n",
    "        \"\"\"\n",
    "        Computes attention scores and applies attention mechanism.\n",
    "\n",
    "        Parameters:\n",
    "        - lstm_output: Tensor [batch_size, seq_len, hidden_dim]\n",
    "        - attention_layer: nn.Linear, attention layer\n",
    "        \n",
    "        Returns:\n",
    "        - weighted_output: Tensor [batch_size, hidden_dim]\n",
    "        \"\"\"\n",
    "        attention_weights = torch.softmax(attention_layer(lstm_output), dim=1)\n",
    "        weighted_output = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return weighted_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the HAN model.\n",
    "\n",
    "        Parameters:\n",
    "        - x: Tensor [batch_size, num_sentences, num_words, embedding_dim] or [batch_size, num_words, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "        - logits: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Preprocess input to ensure it has four dimensions\n",
    "        word_output, _ = self.word_lstm(x)\n",
    "        sentence_input = self.attention(word_output, self.word_attention)\n",
    "        sentence_output, _ = self.sentence_lstm(sentence_input.unsqueeze(1))\n",
    "        document_representation = self.attention(sentence_output, self.sentence_attention)\n",
    "        logits = self.fc(document_representation)\n",
    "        return logits\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Each item in 'batch' is a tuple: (embeddings, label)\n",
    "    - embeddings: shape [seq_len, embedding_dim]\n",
    "    - label: scalar\n",
    "    We'll pad embeddings so they all match the longest seq_len in this batch.\n",
    "    \"\"\"\n",
    "    embeddings_list = [item[0] for item in batch]  # list of [seq_len, embed_dim] tensors\n",
    "    labels_list = [item[1] for item in batch]      # list of label tensors\n",
    "\n",
    "    # Pad embeddings to [batch_size, max_seq_len_in_batch, embed_dim]\n",
    "    padded_embeddings = pad_sequence(embeddings_list, batch_first=True)\n",
    "\n",
    "    # Stack labels, shape [batch_size]\n",
    "    labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "    return padded_embeddings, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = HateSpeechDataset(train_embeddings, y_train.tolist())\n",
    "test_dataset = HateSpeechDataset(test_embeddings, y_test.tolist())\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34251"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(len(train_loader.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 868  # 100 (FastText) + 768 (Bangla BERT)\n",
    "hidden_dim = 256\n",
    "num_classes = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HAN(embedding_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_han(model, \n",
    "             train_loader, \n",
    "             test_loader, \n",
    "             criterion, \n",
    "             optimizer, \n",
    "             epochs, \n",
    "             device, \n",
    "             save_path=None,\n",
    "             early_stopping_patience=None):\n",
    "    \"\"\"\n",
    "    Trains the HAN model and evaluates on the test set after each epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The HAN model to train.\n",
    "    - train_loader (DataLoader): DataLoader for the training data.\n",
    "    - test_loader (DataLoader): DataLoader for the testing/validation data.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): Device to run the model on.\n",
    "    - save_path (str, optional): Path to save the best model. Defaults to None.\n",
    "    - early_stopping_patience (int, optional): Number of epochs with no improvement after which training will be stopped. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current Learning Rate: {current_lr}\")\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} - Training\", leave=False)\n",
    "\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_bar):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(embeddings)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            train_bar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            eval_bar = tqdm(test_loader, desc=f\"Epoch {epoch}/{epochs} - Evaluating\", leave=False)\n",
    "            for embeddings, labels in eval_bar:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - \"\n",
    "              f\"Accuracy: {accuracy:.4f} | \"\n",
    "              f\"Precision: {precision:.4f} | \"\n",
    "              f\"Recall: {recall:.4f} | \"\n",
    "              f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            epochs_no_improve = 0\n",
    "            if save_path:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"Best model saved to {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if early_stopping_patience and epochs_no_improve >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        if save_path:\n",
    "            checkpoint_path = f\"epoch_{epoch}_model.pth\"\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Model checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(f\"Training completed. Best F1 Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"best_model.pth\"\n",
    "early_stopping_patience = 5\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Accuracy: 0.7793 | Precision: 0.7715 | Recall: 0.7695 | F1 Score: 0.7704\n",
      "Best model saved to best_model.pth\n",
      "Model checkpoint saved to epoch_1_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 0.0392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Accuracy: 0.7804 | Precision: 0.7725 | Recall: 0.7717 | F1 Score: 0.7721\n",
      "Best model saved to best_model.pth\n",
      "Model checkpoint saved to epoch_2_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 0.0394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Accuracy: 0.7805 | Precision: 0.7725 | Recall: 0.7738 | F1 Score: 0.7731\n",
      "Best model saved to best_model.pth\n",
      "Model checkpoint saved to epoch_3_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 0.0377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Accuracy: 0.7804 | Precision: 0.7724 | Recall: 0.7730 | F1 Score: 0.7727\n",
      "Model checkpoint saved to epoch_4_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 0.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Accuracy: 0.7793 | Precision: 0.7713 | Recall: 0.7711 | F1 Score: 0.7712\n",
      "Model checkpoint saved to epoch_5_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 0.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Accuracy: 0.7794 | Precision: 0.7713 | Recall: 0.7721 | F1 Score: 0.7717\n",
      "Model checkpoint saved to epoch_6_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Accuracy: 0.7803 | Precision: 0.7723 | Recall: 0.7726 | F1 Score: 0.7725\n",
      "Model checkpoint saved to epoch_7_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 0.0379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Accuracy: 0.7798 | Precision: 0.7718 | Recall: 0.7721 | F1 Score: 0.7719\n",
      "Early stopping triggered.\n",
      "Training completed. Best F1 Score: 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_han(model=model, \n",
    "         train_loader=train_loader, \n",
    "         test_loader=test_loader, \n",
    "         criterion=criterion, \n",
    "         optimizer=optimizer, \n",
    "         epochs=epochs, \n",
    "         device=device, \n",
    "         save_path=save_path,\n",
    "         early_stopping_patience=early_stopping_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 0.4265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Accuracy: 0.7962 | Precision: 0.7892 | Recall: 0.7955 | F1 Score: 0.7914\n",
      "Best model saved to best_model.pth\n",
      "Model checkpoint saved to epoch_1_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 0.4006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Accuracy: 0.8007 | Precision: 0.8002 | Recall: 0.7820 | F1 Score: 0.7878\n",
      "Model checkpoint saved to epoch_2_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 0.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Accuracy: 0.8053 | Precision: 0.7982 | Recall: 0.8038 | F1 Score: 0.8003\n",
      "Best model saved to best_model.pth\n",
      "Model checkpoint saved to epoch_3_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 0.3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Accuracy: 0.8097 | Precision: 0.8055 | Recall: 0.7967 | F1 Score: 0.8002\n",
      "Model checkpoint saved to epoch_4_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 0.3497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Accuracy: 0.8085 | Precision: 0.8087 | Recall: 0.7901 | F1 Score: 0.7961\n",
      "Model checkpoint saved to epoch_5_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 0.3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Accuracy: 0.8063 | Precision: 0.7990 | Recall: 0.8004 | F1 Score: 0.7997\n",
      "Model checkpoint saved to epoch_6_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 0.3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Accuracy: 0.7972 | Precision: 0.7904 | Recall: 0.7974 | F1 Score: 0.7926\n",
      "Model checkpoint saved to epoch_7_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 0.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Accuracy: 0.8034 | Precision: 0.7960 | Recall: 0.7981 | F1 Score: 0.7970\n",
      "Early stopping triggered.\n",
      "Training completed. Best F1 Score: 0.8003\n"
     ]
    }
   ],
   "source": [
    "train_han(model=model, \n",
    "         train_loader=train_loader, \n",
    "         test_loader=test_loader, \n",
    "         criterion=criterion, \n",
    "         optimizer=optimizer, \n",
    "         epochs=epochs, \n",
    "         device=device, \n",
    "         save_path=save_path,\n",
    "         early_stopping_patience=early_stopping_patience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
