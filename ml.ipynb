{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "Requirement already satisfied: fasttext-wheel in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.6.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp310-cp310-win_amd64.whl (203.1 MB)\n",
      "Collecting shap\n",
      "  Using cached shap-0.46.0-cp310-cp310-win_amd64.whl (456 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.0)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: click in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: joblib in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0\n",
      "  Using cached huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fasttext-wheel) (2.13.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fasttext-wheel) (63.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.60.0-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Collecting slicer==0.0.8\n",
      "  Using cached slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0\n",
      "  Using cached llvmlite-0.43.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Installing collected packages: mpmath, sympy, slicer, safetensors, llvmlite, jinja2, fsspec, filelock, cloudpickle, torch, numba, nltk, huggingface-hub, tokenizers, shap, seaborn, transformers\n",
      "Successfully installed cloudpickle-3.1.0 filelock-3.16.1 fsspec-2024.12.0 huggingface-hub-0.27.0 jinja2-3.1.5 llvmlite-0.43.0 mpmath-1.3.0 nltk-3.9.1 numba-0.60.0 safetensors-0.4.5 seaborn-0.13.2 shap-0.46.0 slicer-0.0.8 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 transformers-4.47.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy nltk transformers fasttext-wheel scikit-learn torch shap matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download the Bengali stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load Bengali stopwords\n",
    "bengali_stopwords = set(stopwords.words('bengali'))\n",
    "\n",
    "# Initialize tokenizer for later use\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "                                            sentence  hate category\n",
      "0                     যত্তসব পাপন শালার ফাজলামী!!!!!     1   sports\n",
      "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার     1   sports\n",
      "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...     1   sports\n",
      "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়     1   sports\n",
      "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব     1   sports\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Load the Dataset\n",
    "# Replace 'dataset.csv' with the path to your dataset file\n",
    "file_path = 'bangla_hate_speech.csv'  # Update this with your actual dataset path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to verify data loading\n",
    "print(\"Data Preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Cleaning:\n",
      "                                            sentence  \\\n",
      "0                     যত্তসব পাপন শালার ফাজলামী!!!!!   \n",
      "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
      "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
      "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
      "4   তুই তো শালা গাজা খাইছচ।তুর মার হেডায় খেলবে সাকিব   \n",
      "\n",
      "                                    cleaned_sentence  \n",
      "0                          যত্তসব পাপন শালার ফাজলামী  \n",
      "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার  \n",
      "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...  \n",
      "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়  \n",
      "4    তুই তো শালা গাজা খাইছচতুর মার হেডায় খেলবে সাকিব  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 3: Text Cleaning\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing unnecessary characters and symbols.\n",
    "    \"\"\"\n",
    "    # Remove special characters, numbers, and symbols, keeping only Bengali letters\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Keep Bengali characters and whitespace\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the 'sentence' column\n",
    "df['cleaned_sentence'] = df['sentence'].apply(clean_text)\n",
    "\n",
    "print(\"After Cleaning:\")\n",
    "print(df[['sentence', 'cleaned_sentence']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Tokenization:\n",
      "                                    cleaned_sentence  \\\n",
      "0                          যত্তসব পাপন শালার ফাজলামী   \n",
      "1                  পাপন শালা রে রিমান্ডে নেওয়া দরকার   \n",
      "2  জিল্লুর রহমান স্যারের ছেলে এতো বড় জারজ হবে এটা...   \n",
      "3                শালা লুচ্চা দেখতে পাঠার মত দেখা যায়   \n",
      "4    তুই তো শালা গাজা খাইছচতুর মার হেডায় খেলবে সাকিব   \n",
      "\n",
      "                                              tokens  \n",
      "0      [যত, ##ত, ##সব, পাপন, শালা, ##র, ফাজলাম, ##ী]  \n",
      "1    [পাপন, শালা, রে, রিমান, ##ডে, নেও, ##যা, দরকার]  \n",
      "2  [জিল, ##ল, ##র, রহমান, স, ##যার, ##ের, ছেলে, এ...  \n",
      "3  [শালা, ল, ##চ, ##চা, দেখতে, পাঠ, ##ার, মত, দেখ...  \n",
      "4  [ত, ##ই, তে, ##া, শালা, গাজা, খাই, ##ছ, ##চতর,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 4: Tokenization with Bangla BERT\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenizes text using Bangla BERT tokenizer.\n",
    "    \"\"\"\n",
    "    # Tokenize the text into subwords for better context understanding\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Convert tokens to a single string for training input\n",
    "    return tokens\n",
    "\n",
    "# Tokenize cleaned sentences\n",
    "df['tokens'] = df['cleaned_sentence'].apply(tokenize_text)\n",
    "\n",
    "print(\"After Tokenization:\")\n",
    "print(df[['cleaned_sentence', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Stopword Removal:\n",
      "                                              tokens  \\\n",
      "0      [যত, ##ত, ##সব, পাপন, শালা, ##র, ফাজলাম, ##ী]   \n",
      "1    [পাপন, শালা, রে, রিমান, ##ডে, নেও, ##যা, দরকার]   \n",
      "2  [জিল, ##ল, ##র, রহমান, স, ##যার, ##ের, ছেলে, এ...   \n",
      "3  [শালা, ল, ##চ, ##চা, দেখতে, পাঠ, ##ার, মত, দেখ...   \n",
      "4  [ত, ##ই, তে, ##া, শালা, গাজা, খাই, ##ছ, ##চতর,...   \n",
      "\n",
      "                                     filtered_tokens  \n",
      "0          [##ত, ##সব, পাপন, শালা, ##র, ফাজলাম, ##ী]  \n",
      "1    [পাপন, শালা, রে, রিমান, ##ডে, নেও, ##যা, দরকার]  \n",
      "2  [জিল, ##ল, ##র, রহমান, স, ##যার, ##ের, ছেলে, #...  \n",
      "3           [শালা, ল, ##চ, ##চা, পাঠ, ##ার, মত, ##য]  \n",
      "4  [ত, ##ই, তে, ##া, শালা, গাজা, খাই, ##ছ, ##চতর,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 5: Stopword Removal\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Removes Bengali stopwords from the token list.\n",
    "    \"\"\"\n",
    "    return [token for token in tokens if token not in bengali_stopwords]\n",
    "\n",
    "# Apply stopword removal on tokens\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "\n",
    "print(\"After Stopword Removal:\")\n",
    "print(df[['tokens', 'filtered_tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 24000\n",
      "Testing Data Size: 6000\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare Data for Modeling\n",
    "# Map the sentences and their respective labels\n",
    "X = df['filtered_tokens'].apply(lambda tokens: ' '.join(tokens))  # Join tokens for input\n",
    "y = df['hate']  # Assuming the 'hate' column contains the labels\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Display dataset statistics\n",
    "print(\"Training Data Size:\", len(X_train))\n",
    "print(\"Testing Data Size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Data saved to disk.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 7: Save Preprocessed Data\n",
    "# Save the train and test splits for later use\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "y_train.to_csv('y_train.csv', index=False)\n",
    "X_test.to_csv('X_test.csv', index=False)\n",
    "y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "print(\"Preprocessing complete. Data saved to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from gensim.models import FastText\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText training complete!\n",
      "FastText vector for 'বাংলাদেশ': [-2.93207377e-01 -9.67192203e-02  2.26068422e-01  8.45103711e-02\n",
      " -1.01818047e-01 -2.56076187e-01  5.44458777e-02  6.24997854e-01\n",
      " -3.01259190e-01 -2.64037192e-01 -9.29759890e-02  3.88862878e-01\n",
      "  5.01257218e-02 -1.72663674e-01 -2.25367174e-01  1.17577925e-04\n",
      "  2.78682798e-01 -7.68309176e-01  2.65721846e-02 -5.96940070e-02\n",
      " -3.49264205e-01  4.37141538e-01 -1.29414722e-01  1.65042341e-01\n",
      "  4.27348584e-01 -4.40854579e-01 -1.81770399e-01  1.98105887e-01\n",
      "  2.59890705e-01  4.10499386e-02 -2.85143435e-01  4.05519307e-01\n",
      " -3.30519706e-01  3.43494058e-01  1.33104116e-01 -4.05534923e-01\n",
      "  2.35861167e-01 -2.89712064e-02 -2.29251921e-01 -3.33831102e-01\n",
      "  6.43422067e-01  2.79015750e-01 -2.07290664e-01 -2.65391529e-01\n",
      "  2.53665864e-01 -1.76009789e-01 -2.61550754e-01  5.06602108e-01\n",
      "  1.09816402e-01 -4.24761653e-01  3.24022740e-01 -6.66299909e-02\n",
      "  5.67849159e-01 -2.38398537e-01 -3.40567410e-01  1.73078343e-01\n",
      "  2.49055699e-01 -4.71430600e-01 -9.78461027e-01 -7.11081177e-02\n",
      "  4.66290802e-01  1.69385254e-01  3.15576717e-02 -6.94964290e-01\n",
      "  9.02029499e-02 -4.57410455e-01  4.75363545e-02 -3.22174966e-01\n",
      " -1.70098945e-01  4.24811184e-01 -2.31769100e-01 -2.05045909e-01\n",
      "  5.44849336e-01  8.67341980e-02  3.70458931e-01  5.59164025e-02\n",
      " -1.30993247e-01  6.30099177e-02  7.63669936e-03 -1.95352472e-02\n",
      "  2.08508104e-01  6.92731917e-01  1.03246920e-01  4.45498586e-01\n",
      "  1.02550834e-01  4.62485731e-01 -2.87143916e-01 -2.60047764e-02\n",
      "  3.40006351e-02 -1.49541944e-01  4.71051902e-01  9.94508266e-02\n",
      "  6.41902268e-04  2.01775938e-01 -5.58378957e-02 -7.17078596e-02\n",
      "  7.09536314e-01 -2.73026489e-02  4.39772725e-01  4.53127861e-01]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: FastText Embeddings\n",
    "def train_fasttext(corpus, embedding_dim=100, window_size=5, min_count=1):\n",
    "    \"\"\"\n",
    "    Train a FastText model on the dataset.\n",
    "    :param corpus: List of tokenized sentences.\n",
    "    :param embedding_dim: Dimension of the embeddings.\n",
    "    :param window_size: Context window size.\n",
    "    :param min_count: Minimum word count threshold.\n",
    "    :return: Trained FastText model.\n",
    "    \"\"\"\n",
    "    model = FastText(sentences=corpus, vector_size=embedding_dim, window=window_size, min_count=min_count, sg=1)\n",
    "    return model\n",
    "\n",
    "# Convert the filtered tokens to a list of tokenized sentences\n",
    "corpus = df['filtered_tokens'].tolist()\n",
    "\n",
    "# Train the FastText model\n",
    "fasttext_model = train_fasttext(corpus)\n",
    "print(\"FastText training complete!\")\n",
    "\n",
    "# Example: Retrieve FastText vector for a word\n",
    "word = \"বাংলাদেশ\"\n",
    "if word in fasttext_model.wv:\n",
    "    print(f\"FastText vector for '{word}': {fasttext_model.wv[word]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embeddings shape: torch.Size([8, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Bangla BERT Embeddings\n",
    "# Load Bangla BERT model and tokenizer\n",
    "bangla_bert_model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "bangla_bert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    \"\"\"\n",
    "    Extract BERT embeddings for the input text.\n",
    "    :param text: Input sentence.\n",
    "    :return: Token-level embeddings.\n",
    "    \"\"\"\n",
    "    inputs = bangla_bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bangla_bert_model(**inputs)\n",
    "    # Get the last hidden state (token embeddings)\n",
    "    return outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "# Example: Get Bangla BERT embeddings for a sentence\n",
    "sentence = \"বাংলাদেশ একটি সুন্দর দেশ।\"\n",
    "bert_embeddings = get_bert_embeddings(sentence)\n",
    "print(f\"BERT Embeddings shape: {bert_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Embeddings shape: (7, 868)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 3: Combine FastText and BERT Embeddings\n",
    "def combine_embeddings(tokens, fasttext_model, bert_embeddings, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Combine FastText and BERT embeddings for each token.\n",
    "    :param tokens: List of tokens for the sentence.\n",
    "    :param fasttext_model: Trained FastText model.\n",
    "    :param bert_embeddings: BERT embeddings for the tokens.\n",
    "    :param embedding_dim: Dimension of FastText embeddings.\n",
    "    :return: Combined embeddings for each token.\n",
    "    \"\"\"\n",
    "    combined_embeddings = []\n",
    "    for idx, token in enumerate(tokens):\n",
    "        # Get FastText embedding (zeros if not in vocab)\n",
    "        fasttext_vec = fasttext_model.wv[token] if token in fasttext_model.wv else np.zeros(embedding_dim)\n",
    "        \n",
    "        # Get BERT embedding for the token\n",
    "        bert_vec = bert_embeddings[idx].numpy() if idx < len(bert_embeddings) else np.zeros_like(bert_embeddings[0].numpy())\n",
    "        \n",
    "        # Concatenate FastText and BERT embeddings\n",
    "        combined_vec = np.concatenate((fasttext_vec, bert_vec))\n",
    "        combined_embeddings.append(combined_vec)\n",
    "    \n",
    "    return np.array(combined_embeddings)\n",
    "\n",
    "# Example: Combine embeddings for a sentence\n",
    "tokens = df['filtered_tokens'][0]  # Use the first sentence in the dataset\n",
    "bert_embs = get_bert_embeddings(\" \".join(tokens))\n",
    "combined_embs = combine_embeddings(tokens, fasttext_model, bert_embs)\n",
    "print(f\"Combined Embeddings shape: {combined_embs.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Custom Dataset\n",
    "class HateSpeechDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for loading hate speech data with embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, texts, labels, embeddings):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_embedding = self.embeddings[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(text_embedding, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Define the HAN Model\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(HAN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Word-level BiLSTM\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.word_attention = nn.Linear(2 * hidden_dim, 1)  # Attention layer for words\n",
    "\n",
    "        # Sentence-level BiLSTM\n",
    "        self.sentence_lstm = nn.LSTM(2 * hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.sentence_attention = nn.Linear(2 * hidden_dim, 1)  # Attention layer for sentences\n",
    "\n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(2 * hidden_dim, num_classes)\n",
    "\n",
    "    def attention(self, lstm_output, attention_layer):\n",
    "        \"\"\"\n",
    "        Apply attention mechanism.\n",
    "        \"\"\"\n",
    "        attention_weights = torch.softmax(attention_layer(lstm_output), dim=1)\n",
    "        weighted_output = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return weighted_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Word-level BiLSTM and attention\n",
    "        word_output, _ = self.word_lstm(x)\n",
    "        sentence_input = self.attention(word_output, self.word_attention)\n",
    "\n",
    "        # Sentence-level BiLSTM and attention\n",
    "        sentence_output, _ = self.sentence_lstm(sentence_input.unsqueeze(0))\n",
    "        document_representation = self.attention(sentence_output, self.sentence_attention)\n",
    "\n",
    "        # Classification layer\n",
    "        logits = self.fc(document_representation)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 3: Training and Evaluation Functions\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, labels in train_loader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in val_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_train_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Preparing Data and Training the Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming you have combined embeddings (X_train, X_test) and labels (y_train, y_test)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m HateSpeechDataset(X_train, y_train, \u001b[43mcombined_train_embeddings\u001b[49m)\n\u001b[0;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m HateSpeechDataset(X_test, y_test, combined_test_embeddings)\n\u001b[0;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_train_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Preparing Data and Training the Model\n",
    "# Assuming you have combined embeddings (X_train, X_test) and labels (y_train, y_test)\n",
    "train_dataset = HateSpeechDataset(X_train, y_train, combined_train_embeddings)\n",
    "test_dataset = HateSpeechDataset(X_test, y_test, combined_test_embeddings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Model Parameters\n",
    "embedding_dim = 868  # Example: 100 from FastText + 768 from Bangla BERT\n",
    "hidden_dim = 128\n",
    "num_classes = len(set(y_train))  # Number of unique labels\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = HAN(embedding_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    accuracy, precision, recall, f1 = evaluate_model(model, test_loader, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from gensim.models import FastText\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "bengali_stopwords = set(stopwords.words('bengali'))\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing unnecessary characters and symbols.\"\"\"\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Keep Bengali characters and whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text, tokenizer):\n",
    "    \"\"\"Tokenizes text using Bangla BERT tokenizer.\"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Removes Bengali stopwords from tokens.\"\"\"\n",
    "    return [token for token in tokens if token not in bengali_stopwords]\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"bangla_hate_speech.csv\"  # Replace with actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "df['cleaned_sentence'] = df['sentence'].apply(clean_text)\n",
    "\n",
    "# Load tokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "\n",
    "df['tokens'] = df['cleaned_sentence'].apply(lambda x: tokenize_text(x, bert_tokenizer))\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "\n",
    "# Split data\n",
    "X = df['filtered_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "y = df['hate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Hybrid Embeddings Generation\n",
    "# Train FastText\n",
    "def train_fasttext(corpus, embedding_dim=100):\n",
    "    model = FastText(sentences=corpus, vector_size=embedding_dim, window=5, min_count=1, sg=1)\n",
    "    return model\n",
    "\n",
    "# Prepare corpus for FastText\n",
    "corpus = df['filtered_tokens'].tolist()\n",
    "fasttext_model = train_fasttext(corpus)\n",
    "\n",
    "# Load Bangla BERT\n",
    "bert_model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = bert_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "def combine_embeddings(tokens, fasttext_model, bert_embeddings, embedding_dim=100):\n",
    "    combined_embeddings = []\n",
    "    for idx, token in enumerate(tokens):\n",
    "        fasttext_vec = fasttext_model.wv[token] if token in fasttext_model.wv else np.zeros(embedding_dim)\n",
    "        bert_vec = bert_embeddings[idx].numpy() if idx < len(bert_embeddings) else np.zeros_like(bert_embeddings[0].numpy())\n",
    "        combined_vec = np.concatenate((fasttext_vec, bert_vec))\n",
    "        combined_embeddings.append(combined_vec)\n",
    "    return np.array(combined_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 867/1500 [51:09<37:20,  3.54s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m train_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m X_train]\n\u001b[0;32m     50\u001b[0m test_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m X_test]\n\u001b[1;32m---> 52\u001b[0m train_bert_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_bert_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m test_bert_embeddings \u001b[38;5;241m=\u001b[39m batch_bert_embeddings(test_sentences, bert_tokenizer, bert_model)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_embeddings_optimized\u001b[39m(tokens, fasttext_embeddings, bert_embedding):\n",
      "Cell \u001b[1;32mIn[37], line 42\u001b[0m, in \u001b[0;36mbatch_bert_embeddings\u001b[1;34m(sentences, bert_tokenizer, bert_model, batch_size)\u001b[0m\n\u001b[0;32m     40\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 42\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m bert_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     43\u001b[0m batch_embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     44\u001b[0m all_embeddings\u001b[38;5;241m.\u001b[39mextend(batch_embeddings)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pytorch_utils.py:258\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:640\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    554\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def precompute_fasttext_embeddings(fasttext_model, unique_tokens, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Precompute FastText embeddings for all unique tokens.\n",
    "    :param fasttext_model: Trained FastText model.\n",
    "    :param unique_tokens: Set of unique tokens from the dataset.\n",
    "    :param embedding_dim: Dimension of FastText embeddings.\n",
    "    :return: Dictionary of token to embedding.\n",
    "    \"\"\"\n",
    "    token_embeddings = {}\n",
    "    for token in unique_tokens:\n",
    "        if token in fasttext_model.wv:\n",
    "            token_embeddings[token] = fasttext_model.wv[token]\n",
    "        else:\n",
    "            token_embeddings[token] = np.zeros(embedding_dim)  # OOV tokens\n",
    "    return token_embeddings\n",
    "\n",
    "# Step 1: Precompute FastText Embeddings\n",
    "unique_tokens = set(token for tokens in df['filtered_tokens'] for token in tokens)\n",
    "fasttext_embeddings = precompute_fasttext_embeddings(fasttext_model, unique_tokens)\n",
    "\n",
    "def batch_bert_embeddings(sentences, bert_tokenizer, bert_model, batch_size=16):\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings in batches for efficiency.\n",
    "    :param sentences: List of sentences.\n",
    "    :param bert_tokenizer: Bangla BERT tokenizer.\n",
    "    :param bert_model: Bangla BERT model.\n",
    "    :param batch_size: Number of sentences per batch.\n",
    "    :return: List of BERT embeddings for each sentence.\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    bert_model = bert_model.to(device)\n",
    "    bert_model.eval()\n",
    "    \n",
    "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        inputs = bert_tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state.cpu().numpy()\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return all_embeddings\n",
    "\n",
    "# Step 2: Generate BERT Embeddings in Batches\n",
    "train_sentences = [\" \".join(tokens) for tokens in X_train]\n",
    "test_sentences = [\" \".join(tokens) for tokens in X_test]\n",
    "\n",
    "train_bert_embeddings = batch_bert_embeddings(train_sentences, bert_tokenizer, bert_model)\n",
    "test_bert_embeddings = batch_bert_embeddings(test_sentences, bert_tokenizer, bert_model)\n",
    "\n",
    "def combine_embeddings_optimized(tokens, fasttext_embeddings, bert_embedding):\n",
    "    \"\"\"\n",
    "    Combine FastText and BERT embeddings for each token.\n",
    "    :param tokens: List of tokens for the sentence.\n",
    "    :param fasttext_embeddings: Precomputed FastText embeddings.\n",
    "    :param bert_embedding: BERT embedding for the sentence.\n",
    "    :return: Combined embeddings for the sentence.\n",
    "    \"\"\"\n",
    "    combined_embeddings = []\n",
    "    for idx, token in enumerate(tokens):\n",
    "        fasttext_vec = fasttext_embeddings.get(token, np.zeros(len(next(iter(fasttext_embeddings.values())))))\n",
    "        bert_vec = bert_embedding[idx] if idx < len(bert_embedding) else np.zeros(bert_embedding.shape[1])\n",
    "        combined_vec = np.concatenate((fasttext_vec, bert_vec))\n",
    "        combined_embeddings.append(combined_vec)\n",
    "    return np.array(combined_embeddings)\n",
    "\n",
    "# Step 3: Combine FastText and BERT Embeddings\n",
    "train_embeddings = [\n",
    "    combine_embeddings_optimized(tokens.split(), fasttext_embeddings, bert_emb)\n",
    "    for tokens, bert_emb in zip(X_train, train_bert_embeddings)\n",
    "]\n",
    "\n",
    "test_embeddings = [\n",
    "    combine_embeddings_optimized(tokens.split(), fasttext_embeddings, bert_emb)\n",
    "    for tokens, bert_emb in zip(X_test, test_bert_embeddings)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings for the dataset\n",
    "train_embeddings = [combine_embeddings(tokens.split(), fasttext_model, get_bert_embeddings(\" \".join(tokens.split()))) for tokens in X_train]\n",
    "test_embeddings = [combine_embeddings(tokens.split(), fasttext_model, get_bert_embeddings(\" \".join(tokens.split()))) for tokens in X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Hierarchical Attention Network (HAN)\n",
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.embeddings[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes):\n",
    "        super(HAN, self).__init__()\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.word_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.sentence_lstm = nn.LSTM(2 * hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.sentence_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.fc = nn.Linear(2 * hidden_dim, num_classes)\n",
    "\n",
    "    def attention(self, lstm_output, attention_layer):\n",
    "        attention_weights = torch.softmax(attention_layer(lstm_output), dim=1)\n",
    "        weighted_output = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return weighted_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        word_output, _ = self.word_lstm(x)\n",
    "        sentence_input = self.attention(word_output, self.word_attention)\n",
    "        sentence_output, _ = self.sentence_lstm(sentence_input.unsqueeze(0))\n",
    "        document_representation = self.attention(sentence_output, self.sentence_attention)\n",
    "        logits = self.fc(document_representation)\n",
    "        return logits\n",
    "\n",
    "train_dataset = HateSpeechDataset(train_embeddings, y_train.tolist())\n",
    "test_dataset = HateSpeechDataset(test_embeddings, y_test.tolist())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "embedding_dim = 868  # 100 (FastText) + 768 (Bangla BERT)\n",
    "hidden_dim = 128\n",
    "num_classes = len(set(y_train))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = HAN(embedding_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for embeddings, labels in train_loader:\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in test_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch + 1}: Accuracy = {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
