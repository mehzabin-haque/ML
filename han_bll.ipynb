{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from gensim.models import FastText\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67378, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hate\n",
       "0    36583\n",
       "1    30795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(dataset, stratify_column, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: pd.DataFrame, the input dataset.\n",
    "    - stratify_column: str, the column used for stratified splitting.\n",
    "    - train_ratio: float, the proportion of the dataset for training (default 0.7).\n",
    "    - val_ratio: float, the proportion of the dataset for validation (default 0.2).\n",
    "    - test_ratio: float, the proportion of the dataset for testing (default 0.1).\n",
    "    - random_state: int, random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - train_data, val_data, test_data: pd.DataFrames, the split datasets.\n",
    "    \"\"\"\n",
    "    # Ensure the split ratios sum to 1\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-5, \"Ratios must sum to 1.\"\n",
    "\n",
    "    # Initial train + validation split\n",
    "    train_data, temp_data = train_test_split(\n",
    "        dataset,\n",
    "        test_size=(val_ratio + test_ratio),\n",
    "        random_state=random_state,\n",
    "        stratify=dataset[stratify_column] if stratify_column else None\n",
    "    )\n",
    "\n",
    "    # Split the remaining data into validation and test sets\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data,\n",
    "        test_size=test_ratio / (val_ratio + test_ratio),\n",
    "        random_state=random_state,\n",
    "        stratify=temp_data[stratify_column] if stratify_column else None\n",
    "    )\n",
    "\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shazzad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "bengali_stopwords = set(stopwords.words('bengali'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans text by removing unnecessary characters and symbols.\"\"\"\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', text)  # Keep Bengali characters and whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text, tokenizer):\n",
    "    \"\"\"Tokenizes text using Bangla BERT tokenizer.\"\"\"\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"Removes Bengali stopwords from tokens.\"\"\"\n",
    "    return [token for token in tokens if token not in bengali_stopwords]\n",
    "\n",
    "def preprocess_text(text, tokenizer):\n",
    "    \"\"\"Combines cleaning, tokenization, and stopword removal.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text, tokenizer)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(df, stratify_column='hate')\n",
    "\n",
    "train_data['processed_sentence'] = train_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))\n",
    "val_data['processed_sentence'] = val_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))\n",
    "test_data['processed_sentence'] = test_data['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_sentence'] = df['sentence'].apply(lambda x: preprocess_text(x, bert_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(corpus, embedding_dim=100, window=5, min_count=1, sg=1):\n",
    "    \"\"\"\n",
    "    Trains a FastText embedding model using gensim.\n",
    "\n",
    "    Parameters:\n",
    "    - corpus: list of lists, tokenized sentences.\n",
    "    - embedding_dim: int, size of word vectors.\n",
    "    - window: int, context window size.\n",
    "    - min_count: int, minimum word frequency for inclusion.\n",
    "    - sg: int, skip-gram (1) or CBOW (0).\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained FastText model.\n",
    "    \"\"\"\n",
    "    model = FastText(\n",
    "        sentences=corpus, \n",
    "        vector_size=embedding_dim, \n",
    "        window=window, \n",
    "        min_count=min_count, \n",
    "        sg=sg\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_data['processed_sentence'].tolist()\n",
    "fasttext_model = train_fasttext(corpus)\n",
    "\n",
    "fasttext_model.save(\"fasttext_embeddings.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(sentence_tokens, model):\n",
    "    \"\"\"\n",
    "    Generates sentence embeddings by averaging word embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - sentence_tokens: list, tokens in a sentence.\n",
    "    - model: FastText model.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Sentence embedding vector.\n",
    "    \"\"\"\n",
    "    embeddings = [model.wv[word] for word in sentence_tokens if word in model.wv]\n",
    "    if len(embeddings) == 0:  # Handle case with no valid tokens\n",
    "        return np.zeros(model.vector_size)\n",
    "    return sum(embeddings) / len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fasttext_embedding'] = df['processed_sentence'].apply(lambda tokens: sentence_embedding(tokens, fasttext_model))\n",
    "train_data['fasttext_embedding'] = train_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))\n",
    "val_data['fasttext_embedding'] = val_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))\n",
    "test_data['fasttext_embedding'] = test_data['processed_sentence'].apply(lambda x: sentence_embedding(x, fasttext_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.2294447, -0.0554792, 0.43374178, 0.0877842...\n",
       "1    [-0.09326634, -0.058718935, 0.25895825, 0.0064...\n",
       "2    [-0.15248016, -0.1341862, 0.38996747, 0.208053...\n",
       "3    [-0.24937002, -0.071896076, 0.29962087, 0.0268...\n",
       "4    [-0.1607902, 0.07257928, 0.41274455, 0.0196789...\n",
       "Name: fasttext_embedding, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fasttext_embedding'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            [##ত, ##সব, পাপন, শালা, ##র, ফাজলাম, ##ী]\n",
       "1      [পাপন, শালা, রে, রিমান, ##ডে, নেও, ##যা, দরকার]\n",
       "2    [জিল, ##ল, ##র, রহমান, স, ##যার, ##ের, ছেলে, #...\n",
       "3             [শালা, ল, ##চ, ##চা, পাঠ, ##ার, মত, ##য]\n",
       "4    [ত, ##ই, তে, ##া, শালা, গাজা, খাই, ##ছ, ##চতর,...\n",
       "Name: processed_sentence, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sentence_embedding(text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): Input text\n",
    "    Returns:\n",
    "        torch.Tensor of shape [bert_hidden_size]\n",
    "    \"\"\"\n",
    "    inputs = bert_tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    # Inference with no gradient to save memory and compute\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "\n",
    "    # outputs.last_hidden_state has shape [batch_size, seq_len, hidden_dim]\n",
    "    # If you're only handling a single text, you can squeeze the batch dimension\n",
    "    return outputs.last_hidden_state.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_embeddings(tokens, fasttext_model, bert_embeddings, embedding_dim=100):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tokens (list): List of tokens\n",
    "        fasttext_model: Gensim's FastText model\n",
    "        bert_embeddings (torch.Tensor): BERT embeddings on GPU\n",
    "        embedding_dim (int): Dimension of the FastText embeddings\n",
    "    Returns:\n",
    "        torch.Tensor of shape [len(tokens), embedding_dim + bert_hidden_size]\n",
    "    \"\"\"\n",
    "    combined_embeddings = []\n",
    "\n",
    "    for idx, token in enumerate(tokens):\n",
    "        # 1. Get FastText vector (on CPU), then move to GPU\n",
    "        if token in fasttext_model.wv:\n",
    "            fasttext_vec = fasttext_model.wv[token]\n",
    "        else:\n",
    "            fasttext_vec = np.zeros(embedding_dim)\n",
    "        fasttext_vec = torch.tensor(fasttext_vec, dtype=torch.float32, device=device)\n",
    "\n",
    "        # 2. Get the corresponding BERT embedding (already on GPU)\n",
    "        if idx < bert_embeddings.size(0):\n",
    "            bert_vec = bert_embeddings[idx]\n",
    "        else:\n",
    "            bert_vec = torch.zeros_like(bert_embeddings[0], device=device)\n",
    "\n",
    "        # 3. Concatenate FastText and BERT embedding along the last dimension\n",
    "        combined_vec = torch.cat((fasttext_vec, bert_vec), dim=0)\n",
    "        combined_embeddings.append(combined_vec)\n",
    "\n",
    "    # Convert list of tensors to a single tensor of shape [num_tokens, total_dim]\n",
    "    combined_embeddings = torch.stack(combined_embeddings)\n",
    "    return combined_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_safe(text, fasttext_model):\n",
    "    \"\"\"\n",
    "    Returns a zero embedding if the text is empty\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        # For example, return a zero tensor with shape [1, your_dimension]\n",
    "        # or skip. This is up to your design.\n",
    "        return torch.zeros((1, 868), device=device)  # If your BERT hidden dim is 768\n",
    "    tokens = text.split()\n",
    "    bert_emb = bert_sentence_embedding(\" \".join(tokens))  # get_bert_embeddings also on GPU\n",
    "    return combine_embeddings(tokens, fasttext_model, bert_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['processed_sentence'].apply(lambda tokens: ' '.join(tokens))\n",
    "y = df['hate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train embeddings: 100%|██████████| 53902/53902 [08:40<00:00, 103.65it/s]\n",
      "Generating test embeddings: 100%|██████████| 13476/13476 [02:12<00:00, 101.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = [\n",
    "    get_embeddings_safe(tokens, fasttext_model) \n",
    "    for tokens in tqdm(X_train, desc=\"Generating train embeddings\")\n",
    "]\n",
    "test_embeddings = [\n",
    "    get_embeddings_safe(tokens, fasttext_model) \n",
    "    for tokens in tqdm(X_test, desc=\"Generating test embeddings\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx].float(), torch.tensor(self.labels[idx], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HAN(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_classes, dropout=0.3):\n",
    "        super(HAN, self).__init__()\n",
    "\n",
    "        self.word_lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.word_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.sentence_lstm = nn.LSTM(2 * hidden_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.sentence_attention = nn.Linear(2 * hidden_dim, 1)\n",
    "        self.fc = nn.Linear(2 * hidden_dim, 1)\n",
    "\n",
    "    def attention(self, lstm_output, attention_layer):\n",
    "        \"\"\"\n",
    "        Computes attention scores and applies attention mechanism.\n",
    "\n",
    "        Parameters:\n",
    "        - lstm_output: Tensor [batch_size, seq_len, hidden_dim]\n",
    "        - attention_layer: nn.Linear, attention layer\n",
    "        \n",
    "        Returns:\n",
    "        - weighted_output: Tensor [batch_size, hidden_dim]\n",
    "        \"\"\"\n",
    "        attention_weights = torch.softmax(attention_layer(lstm_output), dim=1)\n",
    "        weighted_output = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return weighted_output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the HAN model.\n",
    "\n",
    "        Parameters:\n",
    "        - x: Tensor [batch_size, num_sentences, num_words, embedding_dim] or [batch_size, num_words, embedding_dim]\n",
    "        \n",
    "        Returns:\n",
    "        - logits: Tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Preprocess input to ensure it has four dimensions\n",
    "        word_output, _ = self.word_lstm(x)\n",
    "        sentence_input = self.attention(word_output, self.word_attention)\n",
    "        sentence_output, _ = self.sentence_lstm(sentence_input.unsqueeze(1))\n",
    "        document_representation = self.attention(sentence_output, self.sentence_attention)\n",
    "        logits = self.fc(document_representation)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Each item in 'batch' is a tuple: (embeddings, label)\n",
    "    - embeddings: shape [seq_len, embedding_dim]\n",
    "    - label: scalar\n",
    "    We'll pad embeddings so they all match the longest seq_len in this batch.\n",
    "    \"\"\"\n",
    "    embeddings_list = [item[0] for item in batch]  # list of [seq_len, embed_dim] tensors\n",
    "    labels_list = [item[1] for item in batch]      # list of label tensors\n",
    "\n",
    "    # Pad embeddings to [batch_size, max_seq_len_in_batch, embed_dim]\n",
    "    padded_embeddings = pad_sequence(embeddings_list, batch_first=True)\n",
    "\n",
    "    # Stack labels, shape [batch_size]\n",
    "    labels_tensor = torch.stack(labels_list)\n",
    "\n",
    "    return padded_embeddings, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset_han = HateSpeechDataset(train_embeddings, y_train.tolist())\n",
    "test_dataset_han = HateSpeechDataset(test_embeddings, y_test.tolist())\n",
    "train_loader_han = DataLoader(train_dataset_han, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader_han = DataLoader(test_dataset_han, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53902"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset_han.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1685"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(len(train_loader_han.dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 868  # 100 (FastText) + 768 (Bangla BERT)\n",
    "hidden_dim = 256\n",
    "num_classes = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HAN(embedding_dim, hidden_dim, num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_han(model, \n",
    "             train_loader, \n",
    "             test_loader, \n",
    "             criterion, \n",
    "             optimizer, \n",
    "             epochs, \n",
    "             device, \n",
    "             save_path=None,\n",
    "             early_stopping_patience=None):\n",
    "    \"\"\"\n",
    "    Trains the HAN model and evaluates on the test set after each epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The HAN model to train.\n",
    "    - train_loader (DataLoader): DataLoader for the training data.\n",
    "    - test_loader (DataLoader): DataLoader for the testing/validation data.\n",
    "    - criterion (nn.Module): Loss function.\n",
    "    - optimizer (torch.optim.Optimizer): Optimizer.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): Device to run the model on.\n",
    "    - save_path (str, optional): Path to save the best model. Defaults to None.\n",
    "    - early_stopping_patience (int, optional): Number of epochs with no improvement after which training will be stopped. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    best_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current Learning Rate: {current_lr}\")\n",
    "\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} - Training\", leave=False)\n",
    "\n",
    "        for batch_idx, (embeddings, labels) in enumerate(train_bar):\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(embeddings).squeeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            train_bar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            eval_bar = tqdm(test_loader, desc=f\"Epoch {epoch}/{epochs} - Evaluating\", leave=False)\n",
    "            for embeddings, labels in eval_bar:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings).squeeze(1)\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs >= 0.5).long()\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{epochs}] - \"\n",
    "              f\"Accuracy: {accuracy:.4f} | \"\n",
    "              f\"Precision: {precision:.4f} | \"\n",
    "              f\"Recall: {recall:.4f} | \"\n",
    "              f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            epochs_no_improve = 0\n",
    "            if save_path:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"Best model saved to {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if early_stopping_patience and epochs_no_improve >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "        # if save_path:\n",
    "        #     checkpoint_path = f\"epoch_{epoch}_model.pth\"\n",
    "        #     torch.save(model.state_dict(), checkpoint_path)\n",
    "        #     print(f\"Model checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    print(f\"Training completed. Best F1 Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"best_model.pth\"\n",
    "early_stopping_patience = 5\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 0.4853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Accuracy: 0.7996 | Precision: 0.7870 | Recall: 0.7698 | F1 Score: 0.7783\n",
      "Best model saved to best_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 0.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Accuracy: 0.8019 | Precision: 0.8563 | Recall: 0.6810 | F1 Score: 0.7586\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 0.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Accuracy: 0.8022 | Precision: 0.7549 | Recall: 0.8401 | F1 Score: 0.7952\n",
      "Best model saved to best_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 0.3993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Accuracy: 0.8075 | Precision: 0.8550 | Recall: 0.6970 | F1 Score: 0.7680\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 0.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Accuracy: 0.7986 | Precision: 0.8792 | Recall: 0.6485 | F1 Score: 0.7464\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 0.3743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Accuracy: 0.8099 | Precision: 0.8255 | Recall: 0.7405 | F1 Score: 0.7807\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Accuracy: 0.8154 | Precision: 0.8213 | Recall: 0.7618 | F1 Score: 0.7904\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 0.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Accuracy: 0.8067 | Precision: 0.7603 | Recall: 0.8428 | F1 Score: 0.7994\n",
      "Best model saved to best_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 0.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Accuracy: 0.8014 | Precision: 0.7470 | Recall: 0.8552 | F1 Score: 0.7974\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 0.3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Accuracy: 0.8152 | Precision: 0.8374 | Recall: 0.7391 | F1 Score: 0.7852\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 0.2822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Accuracy: 0.8160 | Precision: 0.8213 | Recall: 0.7636 | F1 Score: 0.7914\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 0.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Accuracy: 0.8163 | Precision: 0.7929 | Recall: 0.8094 | F1 Score: 0.8011\n",
      "Best model saved to best_model.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 0.2572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Accuracy: 0.8145 | Precision: 0.7980 | Recall: 0.7954 | F1 Score: 0.7967\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 0.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Accuracy: 0.8105 | Precision: 0.8240 | Recall: 0.7443 | F1 Score: 0.7821\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 0.2413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Accuracy: 0.8114 | Precision: 0.8140 | Recall: 0.7615 | F1 Score: 0.7868\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 0.2344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Accuracy: 0.8100 | Precision: 0.8054 | Recall: 0.7706 | F1 Score: 0.7876\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 0.2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Accuracy: 0.8085 | Precision: 0.7877 | Recall: 0.7953 | F1 Score: 0.7915\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 0.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Accuracy: 0.8083 | Precision: 0.8007 | Recall: 0.7729 | F1 Score: 0.7865\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 0.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Accuracy: 0.8047 | Precision: 0.7811 | Recall: 0.7956 | F1 Score: 0.7883\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 0.2070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Accuracy: 0.8045 | Precision: 0.7788 | Recall: 0.7992 | F1 Score: 0.7888\n",
      "--------------------------------------------------\n",
      "Training completed. Best F1 Score: 0.8011\n"
     ]
    }
   ],
   "source": [
    "train_han(model=model, \n",
    "         train_loader=train_loader_han, \n",
    "         test_loader=test_loader_han, \n",
    "         criterion=criterion, \n",
    "         optimizer=optimizer, \n",
    "         epochs=epochs, \n",
    "         device=device, \n",
    "         save_path=save_path,\n",
    "         early_stopping_patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"best_model2.pth\"\n",
    "early_stopping_patience = 5\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 0.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Accuracy: 0.8039 | Precision: 0.7852 | Recall: 0.7860 | F1 Score: 0.7856\n",
      "Best model saved to best_model2.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 0.1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Accuracy: 0.8041 | Precision: 0.7858 | Recall: 0.7855 | F1 Score: 0.7856\n",
      "Best model saved to best_model2.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Accuracy: 0.8030 | Precision: 0.7793 | Recall: 0.7936 | F1 Score: 0.7864\n",
      "Best model saved to best_model2.pth\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 0.1881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Accuracy: 0.8039 | Precision: 0.7855 | Recall: 0.7855 | F1 Score: 0.7855\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 0.1871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Accuracy: 0.8031 | Precision: 0.7849 | Recall: 0.7839 | F1 Score: 0.7844\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 0.1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Accuracy: 0.8028 | Precision: 0.7841 | Recall: 0.7847 | F1 Score: 0.7844\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 0.1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Accuracy: 0.8031 | Precision: 0.7816 | Recall: 0.7897 | F1 Score: 0.7857\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Accuracy: 0.8018 | Precision: 0.7805 | Recall: 0.7880 | F1 Score: 0.7842\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 0.1834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Accuracy: 0.8019 | Precision: 0.7835 | Recall: 0.7828 | F1 Score: 0.7831\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 0.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Accuracy: 0.8021 | Precision: 0.7823 | Recall: 0.7857 | F1 Score: 0.7840\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 0.1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Accuracy: 0.8019 | Precision: 0.7838 | Recall: 0.7824 | F1 Score: 0.7831\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 0.1803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Accuracy: 0.8015 | Precision: 0.7828 | Recall: 0.7829 | F1 Score: 0.7829\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Accuracy: 0.8019 | Precision: 0.7845 | Recall: 0.7813 | F1 Score: 0.7829\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 0.1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Accuracy: 0.8015 | Precision: 0.7823 | Recall: 0.7837 | F1 Score: 0.7830\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Accuracy: 0.8016 | Precision: 0.7836 | Recall: 0.7819 | F1 Score: 0.7828\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Training Loss: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] - Accuracy: 0.8014 | Precision: 0.7828 | Recall: 0.7824 | F1 Score: 0.7826\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Training Loss: 0.1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20] - Accuracy: 0.8016 | Precision: 0.7830 | Recall: 0.7828 | F1 Score: 0.7829\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Training Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20] - Accuracy: 0.8014 | Precision: 0.7820 | Recall: 0.7839 | F1 Score: 0.7829\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Training Loss: 0.1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20] - Accuracy: 0.8014 | Precision: 0.7822 | Recall: 0.7837 | F1 Score: 0.7830\n",
      "--------------------------------------------------\n",
      "Current Learning Rate: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Training Loss: 0.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20] - Accuracy: 0.8015 | Precision: 0.7833 | Recall: 0.7821 | F1 Score: 0.7827\n",
      "--------------------------------------------------\n",
      "Training completed. Best F1 Score: 0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_han(model=model, \n",
    "         train_loader=train_loader_han, \n",
    "         test_loader=test_loader_han, \n",
    "         criterion=criterion, \n",
    "         optimizer=optimizer, \n",
    "         epochs=epochs, \n",
    "         device=device, \n",
    "         save_path=save_path,\n",
    "         early_stopping_patience=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
